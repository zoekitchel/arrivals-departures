---
title: "Temp_Data_All_Years"
output: html_notebook
---
This will all be done in terminal R window. 

```{bash terminal setup}
ssh zoek@amphiprion.deenr.rutgers.edu
conda activate /local/home/zoek/enter/envs/myRenv3_5

```


```{r setup}
library(dplyr)
library(data.table)
library(raster)
library(ncdf4)
library(lubridate)
library(maptools)
library(rgdal)
library(tidyr)
library(ggplot2)

```

I have already converted NetCDF files to grd raster files. 
`col_ext/soda_bottom_sep2019.gri`
`col_ext/soda_bottom_sep2019.grd`
`col_ext/soda_surface_sep2019.gri`
`col_ext/soda_surface_sep2019.grd`

At this point, don't know difference between gri and grd. But, gri is 68.5 MB and .grd is 35.7 KB

```{r load netcdf now rasterbrick files}
soda_bottom <- brick("col_ext/soda_bottom_sep2019.gri")
soda_surface <- brick("col_ext/soda_surface_sep2019.gri")

```

Generating coordinates I need to extract, and then average
```{r generating coordinates to extract from hauls}
load("col_ext/hauls_catch_Dec2017 1.RData")
hauls <- data.table(hauls)
cols <- c("lat", "lon", "region")
latlongyear <- hauls[, cols, with = F]

# set the key to all columns
setkey(latlongyear)

# Get unique lat lon combos
latlongyear.u <- unique(latlongyear[list(lat, lon), nomatch = 0])
```

SET COORDINATE SYSTEM
```{r set coordinate system}
locations <- SpatialPoints(cbind(latlongyear.u$lon, latlongyear.u$lat), 
                            proj4string=CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
jpeg("plots.jpg")
plot(locations)
dev.off()
```

Now, let's extract values 

```{r extracting temperature values at correct GPS points}
system.time(temp_values_sbt <- raster::extract(soda_bottom, locations))
system.time(temp_values_sst <- raster::extract(soda_surface, locations))

#column bind
latlon_temp_values_sbt <- cbind(latlongyear.u, temp_values_sbt)
latlon_temp_values_sst <- cbind(latlongyear.u, temp_values_sst)

```

I need a data.table in long format. This takes a while.

```{r melt temp data}
#surface
system.time(df_long_sst <- melt(latlon_temp_values_sst, measure.vars = 4:ncol(latlon_temp_values_sst),
               variable.name = "dateID", value.name = "temp")
)

#bottom
system.time(df_long_sbt <- melt(latlon_temp_values_sbt, measure.vars = 4:ncol(latlon_temp_values_sbt),
               variable.name = "dateID", value.name = "temp")
)

```

We now have to split the date, and get rid of X

```{r split dateID}
#surface
df_long_sst[, c("year", "month", "day") := tstrsplit(dateID, ".", fixed=TRUE)]

df_long_sst$year <- substr(as.character(df_long_sst$year), 2, 5)

#bottom
df_long_sbt[, c("year", "month", "day") := tstrsplit(dateID, ".", fixed=TRUE)]

df_long_sbt$year <- substr(as.character(df_long_sbt$year), 2, 5)

```

____

First is to average over all points in a region for every month/year combo. This takes a while.
```{r avg over GPS points}
#make sure region, year, and month are all factors
  #surface
  nms <- c("region", "year", "month")
  df_long_sst[, (nms) := lapply(.SD, factor), .SDcols = nms]
  
  #bottom
  df_long_sbt[, (nms) := lapply(.SD, factor), .SDcols = nms]

#average over year
  #surface
  soda_sst_monthavg <- df_long_sst[,list(sst_mean=mean(temp)),by=c("region", "year", "month")]
  #bottom
  soda_sbt_monthavg <- df_long_sbt[,list(sbt_mean=mean(temp)),by=c("region", "year", "month")]
  
  #good time to save

save(soda_sst_monthavg, soda_sbt_monthavg, file = "col_ext/soda_avg_monthly_temps.Rdata")
```
It seems as though the best way to speak to the trawls data set and ask it to look for a specific year/month and then go back from that date by a specified interval is to turn all months into julian months, to eliminate year variable.
```{r convert month year to julian month}
#how many months?
year_month_key <- soda_sst_monthavg[, .N, by = c('year', 'month')][,1:2]
max_julian_month <- nrow(year_month_key)

#sequence of 1:756
julian_months <- seq(1, max_julian_month, by=1)

#makekey
year_month_key <- cbind(year_month_key, "month_julian" = julian_months)


```
I need to use this key to add julian month to data tables for sst and sbt. 
```{r add julian month}
#surface
soda_sst_monthavg <- soda_sst_monthavg[year_month_key, on = c(year = 'year', month = 'month')]

#surface
soda_sbt_monthavg <- soda_sbt_monthavg[year_month_key, on = c(year = 'year', month = 'month')]


```

Make sure that month and year match in characters and class in `hauls` and `soda_s?t_monthavg`

```{r match year month in hauls}
hauls$year <- as.factor(hauls$year)
hauls$month <- as.factor(hauls$month)
setattr(hauls$month,"levels",c('01','02','03','04','05','06','07','08','09','10','11','12'))

#now, add julian day to hauls data table as well

hauls <- hauls[year_month_key, nomatch = 0, on = c(year = 'year', month = 'month')]
```



Now, I have to start taking averages.
First, average over all GPS points in a region for a given year and month (this gives us avg temp per region per month)
Second, group by year, find mean in a year
Second, group by year, max in each year
Second, group by year, min in each year
Third, find difference between min and max for each year

This being said, I think I should think more carefully than this. I need to look a mean, min, max for a year BEFORE the month of the trawl.. this will be a little more complicated than how I've been doing it for sure. 

It also means I have to keep this mega file, and look on demand for temp data, which may not be possible. 

For each haul, look at haul month, and then take data from 12 months before that date. 

```{r averaging temperature values}
#turn region into factor in hauls datatable
hauls$region <- as.factor(hauls$region)

#new columns for loop
#surface
#raw
  hauls[,mean_sst_temp :=numeric(.N)]
  hauls[,max_sst_temp :=numeric(.N)]
  hauls[,min_sst_temp :=numeric(.N)]
  hauls[,seas_sst_temp :=numeric(.N)]
  
  
  #lag raw
  #All column names I'll need
  #new columns
  temp.vars <- c("mean", "max", "min", "seas")
  raw.lag.sst.col.names <- CJ(temp.vars, 1:10)[, paste(temp.vars, 1:10, sep ="_sst_temp_lag")]
  
  #loop to make new column names
  hauls[ ,raw.lag.sst.col.names[1:40]:=numeric(.N) ]
  #ended here
 
  
  #change
  hauls[,mean_sst_temp_change :=numeric(.N)]
  hauls[,max_sst_temp_change :=numeric(.N)]
  hauls[,min_sst_temp_change :=numeric(.N)]
  hauls[,seas_sst_temp_change :=numeric(.N)]


  
  #lag change
   #All column names I'll need
  #new columns
  temp.vars <- c("mean", "max", "min", "seas")
  change.lag.sst.col.names <- CJ(temp.vars, 1:10)[, paste(temp.vars, 1:10, sep ="_sst_temp_change_lag")]
  
  #loop to make new column names
  hauls[ ,change.lag.sst.col.names[1:40]:=numeric(.N) ]
  
#stopped here
  #abs change
  hauls$mean_sst_temp_change_abs <- NA
  hauls$max_sst_temp_change_abs <- NA
  hauls$min_sst_temp_change_abs <- NA
  hauls$seas_sst_temp_change_abs <- NA
  
  
  #lag abs change
  hauls$mean_sst_temp_change_abs_lag1 <- NA
  hauls$mean_sst_temp_change_abs_lag2 <- NA
  hauls$mean_sst_temp_change_abs_lag3 <- NA
  hauls$mean_sst_temp_change_abs_lag4 <- NA
  hauls$mean_sst_temp_change_abs_lag5 <- NA
  hauls$mean_sst_temp_change_abs_lag6 <- NA
  hauls$mean_sst_temp_change_abs_lag7 <- NA
  hauls$mean_sst_temp_change_abs_lag8 <- NA
  hauls$mean_sst_temp_change_abs_lag9 <- NA
  hauls$mean_sst_temp_change_abs_lag10 <- NA
  
  hauls$max_sst_temp_change_abs_lag1 <- NA
  hauls$max_sst_temp_change_abs_lag2 <- NA
  hauls$max_sst_temp_change_abs_lag3 <- NA
  hauls$max_sst_temp_change_abs_lag4 <- NA
  hauls$max_sst_temp_change_abs_lag5 <- NA
  hauls$max_sst_temp_change_abs_lag6 <- NA
  hauls$max_sst_temp_change_abs_lag7 <- NA
  hauls$max_sst_temp_change_abs_lag8 <- NA
  hauls$max_sst_temp_change_abs_lag9 <- NA
  hauls$max_sst_temp_change_abs_lag10 <- NA
  
  hauls$min_sst_temp_change_abs_lag1 <- NA
  hauls$min_sst_temp_change_abs_lag2 <- NA
  hauls$min_sst_temp_change_abs_lag3 <- NA
  hauls$min_sst_temp_change_abs_lag4 <- NA
  hauls$min_sst_temp_change_abs_lag5 <- NA
  hauls$min_sst_temp_change_abs_lag6 <- NA
  hauls$min_sst_temp_change_abs_lag7 <- NA
  hauls$min_sst_temp_change_abs_lag8 <- NA
  hauls$min_sst_temp_change_abs_lag9 <- NA
  hauls$min_sst_temp_change_abs_lag10 <- NA
  
  hauls$seas_sst_temp_change_abs_lag1 <- NA
  hauls$seas_sst_temp_change_abs_lag2 <- NA
  hauls$seas_sst_temp_change_abs_lag3 <- NA
  hauls$seas_sst_temp_change_abs_lag4 <- NA
  hauls$seas_sst_temp_change_abs_lag5 <- NA
  hauls$seas_sst_temp_change_abs_lag6 <- NA
  hauls$seas_sst_temp_change_abs_lag7 <- NA
  hauls$seas_sst_temp_change_abs_lag8 <- NA
  hauls$seas_sst_temp_change_abs_lag9 <- NA
  hauls$seas_sst_temp_change_abs_lag10 <- NA
  

#bottom
  
  
i=1
for (i in 1:nrow(hauls)) {
  this_month_julian <- hauls$month_julian[i] #identify month/year
  this_region <- hauls$region[i] #identify region
  monthstosubtract <- seq(from = 11, by = 12, length.out = 11) 
  
  this_month_julian_reverse <- NA #month/year combo back in time
  for (j in 1:length(monthstosubtract)){
    this_month_julian_reverse[j] <- this_month_julian-monthstosubtract[j]
  }
  #surface raw
  subset_sst <- soda_sst_monthavg[region == this_region & month_julian >= this_month_julian_reverse[1] & soda_sst_monthavg$month_julian <= this_month_julian]
  mean_sst_temp <- mean(subset_sst$sst_mean)
  max_sst_temp <- max(subset_sst$sst_mean)
  min_sst_temp <- min(subset_sst$sst_mean)
  
  seas_sst_temp <- max_sst_temp - min_sst_temp
  
  hauls$mean_sst_temp[i] <- mean_sst_temp
  hauls$max_sst_temp[i] <- max_sst_temp
  hauls$min_sst_temp[i] <- min_sst_temp
  hauls$seas_sst_temp[i] <- seas_sst_temp
  
  #here I saved hauls as it is
  save(hauls, file = "col_ext/hauls_930.Rdata")
  
  #surface raw lags 
  sst_raw_lags <- data.table(lag = raw.lag.sst.col.names, temp = NA)
  for (j in 2:length(this_month_julian_reverse)) {
  subset_sst <- soda_sst_monthavg[region == this_region & month_julian >= this_month_julian_reverse[j] & month_julian <= this_month_julian_reverse[j-1]]
  
  indx <- which(colnames(hauls) == paste0("mean_sst_temp_lag", j-1)) #finds column number with right name
  hauls[(i),(indx) := mean(subset_sst$sst_mean)] #assigns value to that cell
  indx <- which(colnames(hauls) == paste0("max_sst_temp_lag", j-1))
  hauls[(i),(indx) := max(subset_sst$sst_mean)]
  indx <- which(colnames(hauls) == paste0("min_sst_temp_lag", j-1))
  hauls[(i),(indx) := min(subset_sst$sst_mean)]
  indx <- which(colnames(hauls) == paste0("seas_sst_temp_lag", j-1))
  hauls[(i),(indx) := (get(paste0("max_sst_temp_lag", j-1))-get(paste0("min_sst_temp_lag", j-1)))]
  }
  
  #surface raw change
  indx <- which(colnames(hauls) == paste0("mean_sst_temp_change"))
  hauls[(i),mean_sst_temp_change :=  mean_sst_temp_lag1[i]-mean_sst_temp[i]]
  hauls[(i),max_sst_temp_change :=  max_sst_temp_lag1[i]-max_sst_temp[i]]
  hauls[(i),min_sst_temp_change :=  min_sst_temp_lag1[i]-min_sst_temp[i]]
  hauls[(i),seas_sst_temp_change :=  seas_sst_temp_lag1[i]-seas_sst_temp[i]]
    
    
    
    
    
    
    
    
    
  
  #surface lag change
}
```



I currently have mean monthly values for a ton of GPS points within a region.
For temperature values, I will first take a mean for each month over the whole region, so then I have a mean month/year value. region_*month*_mean_sst
Then, I will take mean of mean month/year of year of trawl to get a YEARLY mean to represent the whole region. region_year_mean_sst
For maximum temperature experienced in a year, I will take maximum of mean month/year and for minimum I will take minimum of mean month/year. region_year_max_sst, region_year_min_sst
I intend to look at 10 years of possible lags. 

Therefore, the next step is to merge these data with which regions link to which GPS points using hauls$region

First, I will make a lat lon region key

```{r}
latlongreg.key <- latlongyear[,c(1,2,4)]
head(latlongyear)
```

Then I will link data table with GPS and date and temp with regions using above key, and then take appropriate averages

```{r link GPS points with regions}
date_temp_reg <- df_long[latlongreg.key, nomatch = 0, on = c("lat","lon")] #this takes a while

date_temp_reg <- date_temp_reg[,list(mean_month_temp=mean(temp)),by=c("region", "year", "month")]
date_temp_reg <- date_temp_reg[,list(region_year_mean_sst = mean(mean_month_temp), region_year_max_sst = max(mean_month_temp), region_year_min_sst = min(mean_month_temp)), by = c("region", "year")]
date_temp_reg <- date_temp_reg[,region_year_seas_sst := region_year_max_sst - region_year_min_sst, by = c("region", "year")] #this way of adding columns keeps other columns

save(date_temp_reg, file = "date_ssttemp_avg_SODA.Rdata")

ggplot(data=date_temp_reg_avg, aes(x=year, y=region_year_mean_sst)) +
  geom_point() +
  facet_wrap(~region)
base::nrow(date_temp_reg_avg)
```

I now have the predictor values I need, yearly min and max for entire region per year

Next step is to calculate change in temp from previous year to now, luckily I can farm this code from 27_acf_timeseries_analysis_covariates.R

I think I should calculate both change in temperature and lags from date_temp_reg_avg in order to keep years not actually surveyed (i.e. triennial west coast survey)

Here I am first adding lags
```{r}
#adding lag values (1, 2, 3, 4, 5) for seasonality and change in temperature
nm1 <- grep("*sst*", colnames(date_temp_reg_avg), value=TRUE)
nm2 <- paste("lag1", nm1, sep=".")
nm3 <- paste("lag2", nm1, sep=".")
nm4 <- paste("lag3", nm1, sep=".")
nm5 <- paste("lag4", nm1, sep=".")
nm6 <- paste("lag5", nm1, sep=".")
nm7 <- paste("lag6", nm1, sep=".")
nm8 <- paste("lag7", nm1, sep=".")
nm9 <- paste("lag8", nm1, sep=".")
nm10 <- paste("lag9", nm1, sep=".")
nm11 <- paste("lag10", nm1, sep=".")
date_temp_reg_avg_withlags <- data.table(date_temp_reg_avg)
date_temp_reg_avg_withlags[, (nm2) :=  data.table::shift(.SD, n=1, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm3) :=  data.table::shift(.SD, n=2, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm4) :=  data.table::shift(.SD, n=3, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm5) :=  data.table::shift(.SD, n=4, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm6) :=  data.table::shift(.SD, n=5, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm7) :=  data.table::shift(.SD, n=6, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm8) :=  data.table::shift(.SD, n=7, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm9) :=  data.table::shift(.SD, n=8, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm10) :=  data.table::shift(.SD, n=9, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm11) :=  data.table::shift(.SD, n=10, type = "lag"), by=region, .SDcols=nm1]
```

Now, I'm adding change since last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change") := (region_year_mean_sst - lag1.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change") := (region_year_max_sst - lag1.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change") := (region_year_min_sst - lag1.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change") := (region_year_seas_sst - lag1.region_year_seas_sst)]
```
Change experienced last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_seas_sst)]
```
Change experienced 2 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_seas_sst)]
```
Change experienced 3 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_seas_sst)]
```
Change experienced 4 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_seas_sst)]
```
Change experienced 5 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_seas_sst)]
```
Change experienced 6 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_seas_sst)]
```
Change experienced 7 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_seas_sst)]
```
Change experienced 8 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_seas_sst)]
```
Change experienced 9 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_seas_sst)]
```
From Ryan's famous plot, we are more concerned with absolute value of change!
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_abs") := abs(sst_mean_change)]
date_temp_reg_avg_withlags[,c("sst_max_change_abs") := abs(sst_max_change)]
date_temp_reg_avg_withlags[,c("sst_min_change_abs") := abs(sst_min_change)]
date_temp_reg_avg_withlags[,c("sst_seas_change_abs") := abs(sst_seas_change)]
```
Abs Change experienced last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag1_abs") := abs(lag1.region_year_mean_sst - lag2.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag1_abs") := abs(lag1.region_year_max_sst - lag2.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag1_abs") := abs(lag1.region_year_min_sst - lag2.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag1_abs") := abs(lag1.region_year_seas_sst - lag2.region_year_seas_sst)]
```
Abs Change experienced 2 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag2_abs") := abs(lag2.region_year_mean_sst - lag3.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag2_abs") := abs(lag2.region_year_max_sst - lag3.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag2_abs") := abs(lag2.region_year_min_sst - lag3.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag2_abs") := abs(lag2.region_year_seas_sst - lag3.region_year_seas_sst)]
```
Abs Change experienced 3 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag3_abs") := abs(lag3.region_year_mean_sst - lag4.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag3_abs") := abs(lag3.region_year_max_sst - lag4.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag3_abs") := abs(lag3.region_year_min_sst - lag4.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag3_abs") := abs(lag3.region_year_seas_sst - lag4.region_year_seas_sst)]
```
Abs Change experienced 4 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag4_abs") := abs(lag4.region_year_mean_sst - lag5.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag4_abs") := abs(lag4.region_year_max_sst - lag5.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag4_abs") := abs(lag4.region_year_min_sst - lag5.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag4_abs") := abs(lag4.region_year_seas_sst - lag5.region_year_seas_sst)]
```
Abs Change experienced 5 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag5_abs") := abs(lag5.region_year_mean_sst - lag6.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag5_abs") := abs(lag5.region_year_max_sst - lag6.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag5_abs") := abs(lag5.region_year_min_sst - lag6.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag5_abs") := abs(lag5.region_year_seas_sst - lag6.region_year_seas_sst)]
```
Abs Change experienced 6 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag6_abs") := abs(lag6.region_year_mean_sst - lag7.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag6_abs") := abs(lag6.region_year_max_sst - lag7.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag6_abs") := abs(lag6.region_year_min_sst - lag7.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag6_abs") := abs(lag6.region_year_seas_sst - lag7.region_year_seas_sst)]
```
Abs Change experienced 7 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag7_abs") := abs(lag7.region_year_mean_sst - lag8.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag7_abs") := abs(lag7.region_year_max_sst - lag8.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag7_abs") := abs(lag7.region_year_min_sst - lag8.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag7_abs") := abs(lag7.region_year_seas_sst - lag8.region_year_seas_sst)]
```
Abs Change experienced 8 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag8_abs") := abs(lag8.region_year_mean_sst - lag9.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag8_abs") := abs(lag8.region_year_max_sst - lag9.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag8_abs") := abs(lag8.region_year_min_sst - lag9.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag8_abs") := abs(lag8.region_year_seas_sst - lag9.region_year_seas_sst)]
```
Let's git rid of any rows with any NA's (any important ones shouldn't have any) and then save all these goodies!!
```{r}
date_temp_reg_avg_withlags.naomit <- na.omit(date_temp_reg_avg_withlags)
save(date_temp_reg_avg_withlags.naomit, file = "date_ssttemp_avg_SODA_withlags.Rdata")
```

Another way to look at lags, but this isn't appropriate for the binomials I'm currently looking at

```{r}
ccf()
```