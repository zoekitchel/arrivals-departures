---
title: "Temp_Data_All_Years"
output: html_notebook
---
This will all be done in terminal R window. 

```{r setup}
library(dplyr)
library(data.table)
library(raster)
library(ncdf4)
library(lubridate)
library(maptools)
library(rgdal)
library(tidyr)
library(ggplot2)

```

I have already converted NetCDF files to grd raster files. 
`col_ext/soda_bottom_sep2019.gri`
`col_ext/soda_bottom_sep2019.grd`
`col_ext/soda_surface_sep2019.gri`
`col_ext/soda_surface_sep2019.grd`

At this point, don't know difference between gri and grd. But, gri is 68.5 MB and .grd is 35.7 KB

```{r load netcdf now rasterbrick files}
soda_bottom <- brick("soda_bottom_sep2019.gri")
soda_bottom <- brick("soda_surface_sep2019.gri")

```

Generating coordinates I need to extract, and then average
```{r generating coordinates to extract from hauls}
load("col_ext/hauls_catch_Dec2017 1.RData")
hauls <- data.table(hauls)
cols <- c("lat", "lon", "region")
latlongyear <- hauls[, cols, with = F]

# set the key to all columns
setkey(latlongyear)

# Get unique lat lon combos
latlongyear.u <- unique(latlongyear[list(lat, lon), nomatch = 0])
```

New column in newlatlongyear with "X1958.01.01" format, looks like I may not need to do this after all... *SKIPPING FOR NOW*
*this takes a super long time to run, so we should save this result
```{r}


newlatlongyear[, month_digits := ifelse(month < 10, paste0("0", month), month)][, day := paste0("0", c(1))][, year_digits := paste0("X", newlatlongyear$year)]
newlatlongyear[, ID := paste(newlatlongyear$year_digits, newlatlongyear$month_digits, newlatlongyear$day, sep=".")]

newlatlongyear <- transform(newlatlongyear, lat = as.numeric(lat), lon = as.numeric(lon))
newlatlongyear[, lat := as.numeric(lat)][, lon := as.numeric(lon)]

vec <- c("ID", "lat", "lon")
newlatlongyearID <- newlatlongyear[, vec, with=FALSE]

save(newlatlongyear, newlatlongyearID, file = "newlatlongyear.Rdata")

```

SET COORDINATE SYSTEM
```{r set coordinate system}
locations <- SpatialPoints(cbind(latlongyear.u$lon, latlongyear.u$lat), 
                            proj4string=CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
jpeg("plots.jpg")
plot(locations)
dev.off()
```

Now, let's extract values 

```{r extracting temperature values at correct GPS points}
system.time(temp_values_sbt <- raster::extract(soda_bottom, locations))
system.time(temp_values_sst <- raster::extract(soda_surface, locations))

#column bind
latlon_temp_values_sbt <- cbind(latlongyear.u, temp_values_sbt)
latlon_temp_values_sst <- cbind(latlongyear.u, temp_values_sst)

```

I need a data.table in long format. This takes a while.

```{r melt temp data}
#surface
system.time(df_long_sst <- melt(latlon_temp_values_sst, measure.vars = 3:ncol(latlon_temp_values_sst),
               variable.name = "dateID", value.name = "temp")
)

#bottom
system.time(df_long_sbt <- melt(latlon_temp_values_sst, measure.vars = 3:ncol(latlon_temp_values_sbt),
               variable.name = "dateID", value.name = "temp")
)
```
There is a warning as I'm coercing Xxxxx.xx.xx to character, and for some reason not all are characters already, but this seems fine

We now have to split the date back up unfortunately, and get rid of X

```{r split dateID}
#surface
df_long_sst[, c("year", "month", "day") := tstrsplit(dateID, ".", fixed=TRUE)]

df_long_sst$year <- substr(as.character(df_long_sst$year), 2, 5)

#bottom
df_long_sbt[, c("year", "month", "day") := tstrsplit(dateID, ".", fixed=TRUE)]

df_long_sbt$year <- substr(as.character(df_long_sbt$year), 2, 5)

```
____


Now, I have to start taking averages.
First, average over all GPS points in a region for a given year and month (this gives us avg temp per region per month)
Second, group by year, find mean in a year
Second, group by year, max in each year
Second, group by year, min in each year
Third, find difference between min and max for each year

This being said, I think I should think more carefully than this. I need to look a mean, min, max for a year BEFORE the month of the trawl.. this will be a little more complicated than how I've been doing it for sure. 

It also means I have to keep this mega file, and look on demand for temp data, which may not be possible. 

For each haul, look at haul month, and then take data from 12 months before that date. 


I currently have mean monthly values for a ton of GPS points within a region.
For temperature values, I will first take a mean for each month over the whole region, so then I have a mean month/year value. region_*month*_mean_sst
Then, I will take mean of mean month/year of year of trawl to get a YEARLY mean to represent the whole region. region_year_mean_sst
For maximum temperature experienced in a year, I will take maximum of mean month/year and for minimum I will take minimum of mean month/year. region_year_max_sst, region_year_min_sst
I intend to look at 10 years of possible lags. 

Therefore, the next step is to merge these data with which regions link to which GPS points using hauls$region

First, I will make a lat lon region key

```{r}
latlongreg.key <- latlongyear[,c(1,2,4)]
head(latlongyear)
```

Then I will link data table with GPS and date and temp with regions using above key, and then take appropriate averages

```{r link GPS points with regions}
date_temp_reg <- df_long[latlongreg.key, nomatch = 0, on = c("lat","lon")] #this takes a while

date_temp_reg <- date_temp_reg[,list(mean_month_temp=mean(temp)),by=c("region", "year", "month")]
date_temp_reg <- date_temp_reg[,list(region_year_mean_sst = mean(mean_month_temp), region_year_max_sst = max(mean_month_temp), region_year_min_sst = min(mean_month_temp)), by = c("region", "year")]
date_temp_reg <- date_temp_reg[,region_year_seas_sst := region_year_max_sst - region_year_min_sst, by = c("region", "year")] #this way of adding columns keeps other columns

save(date_temp_reg, file = "date_ssttemp_avg_SODA.Rdata")

ggplot(data=date_temp_reg_avg, aes(x=year, y=region_year_mean_sst)) +
  geom_point() +
  facet_wrap(~region)
base::nrow(date_temp_reg_avg)
```

I now have the predictor values I need, yearly min and max for entire region per year

Next step is to calculate change in temp from previous year to now, luckily I can farm this code from 27_acf_timeseries_analysis_covariates.R

I think I should calculate both change in temperature and lags from date_temp_reg_avg in order to keep years not actually surveyed (i.e. triennial west coast survey)

Here I am first adding lags
```{r}
#adding lag values (1, 2, 3, 4, 5) for seasonality and change in temperature
nm1 <- grep("*sst*", colnames(date_temp_reg_avg), value=TRUE)
nm2 <- paste("lag1", nm1, sep=".")
nm3 <- paste("lag2", nm1, sep=".")
nm4 <- paste("lag3", nm1, sep=".")
nm5 <- paste("lag4", nm1, sep=".")
nm6 <- paste("lag5", nm1, sep=".")
nm7 <- paste("lag6", nm1, sep=".")
nm8 <- paste("lag7", nm1, sep=".")
nm9 <- paste("lag8", nm1, sep=".")
nm10 <- paste("lag9", nm1, sep=".")
nm11 <- paste("lag10", nm1, sep=".")
date_temp_reg_avg_withlags <- data.table(date_temp_reg_avg)
date_temp_reg_avg_withlags[, (nm2) :=  data.table::shift(.SD, n=1, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm3) :=  data.table::shift(.SD, n=2, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm4) :=  data.table::shift(.SD, n=3, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm5) :=  data.table::shift(.SD, n=4, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm6) :=  data.table::shift(.SD, n=5, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm7) :=  data.table::shift(.SD, n=6, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm8) :=  data.table::shift(.SD, n=7, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm9) :=  data.table::shift(.SD, n=8, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm10) :=  data.table::shift(.SD, n=9, type = "lag"), by=region, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm11) :=  data.table::shift(.SD, n=10, type = "lag"), by=region, .SDcols=nm1]
```

Now, I'm adding change since last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change") := (region_year_mean_sst - lag1.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change") := (region_year_max_sst - lag1.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change") := (region_year_min_sst - lag1.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change") := (region_year_seas_sst - lag1.region_year_seas_sst)]
```
Change experienced last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_seas_sst)]
```
Change experienced 2 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_seas_sst)]
```
Change experienced 3 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_seas_sst)]
```
Change experienced 4 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_seas_sst)]
```
Change experienced 5 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_seas_sst)]
```
Change experienced 6 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_seas_sst)]
```
Change experienced 7 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_seas_sst)]
```
Change experienced 8 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_seas_sst)]
```
Change experienced 9 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_seas_sst)]
```
From Ryan's famous plot, we are more concerned with absolute value of change!
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_abs") := abs(sst_mean_change)]
date_temp_reg_avg_withlags[,c("sst_max_change_abs") := abs(sst_max_change)]
date_temp_reg_avg_withlags[,c("sst_min_change_abs") := abs(sst_min_change)]
date_temp_reg_avg_withlags[,c("sst_seas_change_abs") := abs(sst_seas_change)]
```
Abs Change experienced last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag1_abs") := abs(lag1.region_year_mean_sst - lag2.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag1_abs") := abs(lag1.region_year_max_sst - lag2.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag1_abs") := abs(lag1.region_year_min_sst - lag2.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag1_abs") := abs(lag1.region_year_seas_sst - lag2.region_year_seas_sst)]
```
Abs Change experienced 2 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag2_abs") := abs(lag2.region_year_mean_sst - lag3.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag2_abs") := abs(lag2.region_year_max_sst - lag3.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag2_abs") := abs(lag2.region_year_min_sst - lag3.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag2_abs") := abs(lag2.region_year_seas_sst - lag3.region_year_seas_sst)]
```
Abs Change experienced 3 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag3_abs") := abs(lag3.region_year_mean_sst - lag4.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag3_abs") := abs(lag3.region_year_max_sst - lag4.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag3_abs") := abs(lag3.region_year_min_sst - lag4.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag3_abs") := abs(lag3.region_year_seas_sst - lag4.region_year_seas_sst)]
```
Abs Change experienced 4 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag4_abs") := abs(lag4.region_year_mean_sst - lag5.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag4_abs") := abs(lag4.region_year_max_sst - lag5.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag4_abs") := abs(lag4.region_year_min_sst - lag5.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag4_abs") := abs(lag4.region_year_seas_sst - lag5.region_year_seas_sst)]
```
Abs Change experienced 5 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag5_abs") := abs(lag5.region_year_mean_sst - lag6.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag5_abs") := abs(lag5.region_year_max_sst - lag6.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag5_abs") := abs(lag5.region_year_min_sst - lag6.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag5_abs") := abs(lag5.region_year_seas_sst - lag6.region_year_seas_sst)]
```
Abs Change experienced 6 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag6_abs") := abs(lag6.region_year_mean_sst - lag7.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag6_abs") := abs(lag6.region_year_max_sst - lag7.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag6_abs") := abs(lag6.region_year_min_sst - lag7.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag6_abs") := abs(lag6.region_year_seas_sst - lag7.region_year_seas_sst)]
```
Abs Change experienced 7 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag7_abs") := abs(lag7.region_year_mean_sst - lag8.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag7_abs") := abs(lag7.region_year_max_sst - lag8.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag7_abs") := abs(lag7.region_year_min_sst - lag8.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag7_abs") := abs(lag7.region_year_seas_sst - lag8.region_year_seas_sst)]
```
Abs Change experienced 8 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag8_abs") := abs(lag8.region_year_mean_sst - lag9.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag8_abs") := abs(lag8.region_year_max_sst - lag9.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag8_abs") := abs(lag8.region_year_min_sst - lag9.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag8_abs") := abs(lag8.region_year_seas_sst - lag9.region_year_seas_sst)]
```
Let's git rid of any rows with any NA's (any important ones shouldn't have any) and then save all these goodies!!
```{r}
date_temp_reg_avg_withlags.naomit <- na.omit(date_temp_reg_avg_withlags)
save(date_temp_reg_avg_withlags.naomit, file = "date_ssttemp_avg_SODA_withlags.Rdata")
```

Another way to look at lags, but this isn't appropriate for the binomials I'm currently looking at

```{r}
ccf()
```