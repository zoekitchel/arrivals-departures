---
title: "Temp_Data_All_Years"
output: html_notebook
---

```{r setup}
library(dplyr)
library(data.table)
library(here)
library(raster)
library(ncdf4)
library(lubridate)
library(maptools)
library(rgdal)
library(tidyr)
library(ggplot2)

load("/Users/zoekitchel/Documents/grad school/Rutgers/Coursework/Fall 2018/SDM/hauls_catch_Dec2017 1.RData")
```

First, I will make list of GPS points and days/year ranges for which I need temperatures, keeping in mind I want to be able to look at lags of 10, and therefore I need to extend time back by 10. (1953 to be safe)

```{r compiling lat, long, year}
latlongyear <- hauls %>%
  dplyr::select(lat, lon, month, year, region)

#add years back to 1953
#for each group, find first year, then generate new observations with repeated GPS sequence going back 10 years

#regions
regions <- levels(as.factor(hauls$region))

newlatlongyear <- data.frame(matrix(ncol = 5, nrow = 0))

colnames(newlatlongyear) <- c("lat", "lon", "month", "year", "region")

for (i in 1:length(regions)) {
  subset <- latlongyear[latlongyear$region == regions[i],]
  minyear <- min(subset$year)
  newminyear <- minyear - 10
  minyearplus10 <- minyear + 10
  
  yearstoadd <- seq(newminyear, (minyear - 1))
  
  subsetlatlong <- subset[subset$year < minyearplus10,]#subset lat lon values used in first 10 years of survey
  subsetlatlong.noreg <- subsetlatlong[,c(1:3)] #don't need column with location or year anymore
  
  subsetlatlong.m <- subsetlatlong.noreg %>%
    unite("latlongmonth", c("lat", "lon", "month") , sep = "_", remove = TRUE) #merge lat lon to expand grid
  
  subsetlatlong.m.vector <- subsetlatlong.m$latlongmonth
  
  tempdf <- expand.grid(subsetlatlong.m.vector, yearstoadd)
  
  tempdf.sep <- separate(tempdf, Var1, c("lat", "lon", "month"), sep = "_", remove = T)
  colnames(tempdf.sep)[colnames(tempdf.sep)=="Var2"] <- "year"
  tempdf.sep$region <- regions[i]
  
  newlatlongyear <- rbind(newlatlongyear, tempdf.sep)
  
} # this for loop generates latitude year combinations for 10 years before sampling began to allow us to look at lags up to 10 years with no NA's

#now, we will merge these data with our latlongyear data from hauls
latlongyear_10yrboost <-rbind(latlongyear, newlatlongyear)

summary(latlongyear_10yrboost)

latlongyear_10yrboost$lat <- as.numeric(latlongyear_10yrboost$lat)
latlongyear_10yrboost$lon <- as.numeric(latlongyear_10yrboost$lon)
latlongyear_10yrboost$month <- as.numeric(latlongyear_10yrboost$month)
latlongyear_10yrboost$region <- as.factor(latlongyear_10yrboost$region)
```

Okay, now getting SODA data
Where I got the data to match soda in trawlData (following Ryan's readme)
Soda Data Files

 1. [Go Here](https://iridl.ldeo.columbia.edu/SOURCES/.CARTON-GIESE/.SODA/.v2p2p4/.temp/time/%28Jan%201953%29%28Dec%202008%29RANGEEDGES/depth/%285.01%29%285.01%29RANGEEDGES/lat/%280N%29%2889.5N%29RANGEEDGES/lon/%28-200E%29%2820E%29RANGEEDGES/datafiles.html)

 2. Restrict ranges as follows for SST to match SODA in trawlData

 	-200E to 20E --> 440 pts

 	0N to 89.5N --> 179 pts

 	5.01 to 5.01

 	Jan 1958 to Dec 2008 --> 672 pts


 3. Stop Selecting

 4. Click Data Files

 5. Download NetCDF Format
 6. File is too big for GitHub, so compress, mine compressed to 95mb using Keka to 7zip

```{r import SODA temperature data}
cp <- nc_open("/Users/zoekitchel/Documents/grad school/Rutgers/LabWork/Colonization_Extinction/CARTON-GIESE_SODA_v2p1p6_sstemp.nc")
print(cp)

# =========================================
# = Function to Read in SODA, Grab Surface =
# =========================================
get.soda.sst <- function(file){

	soda.info <- nc_open(file)
	name.soda.sizes <- sapply(soda.info$var$temp$dim, function(x)x$name)
	soda.sizes <- soda.info$var$temp$size
	dim.units <- sapply(soda.info$var$temp$dim, function(x)x$units)
	print(dim.units)
	stopifnot(grepl("months since ", dim.units[4])) # make sure time is in correct units and in right place
	names(soda.sizes) <- name.soda.sizes
	ntime <- soda.sizes["time"]
	ndepth <- soda.sizes["depth"]

	soda.time0 <- soda.info$var$temp$dim[[4]]$vals
	ref.date <- as.Date(gsub("months since ", "", dim.units[4]))
	start.before.ref <- grepl("-", soda.time0[1]) # is the first date before ref.date?
	n.month.before <- ceiling(abs(soda.time0[1])) + as.integer(start.before.ref)
	start.increment <- ifelse(start.before.ref, "-1 month", "1 month")
	time.start <- rev(seq.Date(ref.date, by=start.increment, length.out=n.month.before))[1]
	soda.time <- seq.Date(time.start, by="1 month", length.out=ntime)
	
	soda.sst <- brick(file)
	names(soda.sst) <- soda.time

		
	return(soda.sst)
	
}


## Using Ryan's code
soda_sst <- get.soda.sst("/Users/zoekitchel/Documents/grad school/Rutgers/LabWork/Colonization_Extinction/CARTON-GIESE_SODA_v2p1p6_sstemp.nc")
soda_sst

plot(soda_sst[[9]])

saveRDS(soda_sst, "SODA2.1.6_SST.rds")
```

New column in latlongyear_10yrboost with "X1958.01.01" format, looks like I may not need to do this after all... SKIPPING FOR NOW
```{r}
latlongyear_10yrboost$month_digits <- NA
for (i in 1:nrow(latlongyear_10yrboost)) {
  if (latlongyear_10yrboost$month[[i]] < 10) {
    latlongyear_10yrboost$month_digits[[i]] <- paste0("0", latlongyear_10yrboost$month[[i]])
  } else {
    latlongyear_10yrboost$month_digits[[i]] <- paste0(latlongyear_10yrboost$month[[i]])
  }
}
latlongyear_10yrboost$day <- paste0("0", c(1))
latlongyear_10yrboost$year_digits <- paste0("X", latlongyear_10yrboost$year)
latlongyear_10yrboost$ID <- paste(latlongyear_10yrboost$year_digits, latlongyear_10yrboost$month_digits, latlongyear_10yrboost$day, sep=".")
latlongyear_10yrboostIDonly <- latlongyear_10yrboost %>%
  dplyr::select(ID, lat, lon)

```

SET COORDINATE SYSTEM
```{r set coordinate system}
locations <- SpatialPoints(cbind(latlongyear_10yrboost$lon, latlongyear_10yrboost$lat), 
                            proj4string=CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
plot(locations)
```

Now, let's extract values *NB: if they do a correct sampling method, this shouldn't be a problem, but is there any world in which we should be averaging temperature values in a different way? here, we're just using the trawl data points, should it be rather the whole region?*

```{r extracting temperature values at correct GPS points}
temp_values <- raster::extract(soda_sst, locations)

justlatlong <- latlongyear_10yrboost %>%
  dplyr::select(lat, lon)

df <- cbind(justlatlong, temp_values)
subset(df, is.na(df[,4])) #looking for NA's
```
Let's look at the problem rows, GOOD NEWS, the problem is that we have a few GPS locations of trawls lacking datapoints, luckily, we can just get rid of these points when averaging!!
```{r}
#now, to make my life easier, I'm just gonna remove NA's here
df_na_rm <- df[complete.cases(df[,4]), ]
head(df_na_rm, rows=10, cols=10)
df_long <- gather(df_na_rm, key = "ID", value = "temp", 3:614 )
head(df_long)
```

We now have to split the date back up unfortunately, and get rid of X

```{r}
rm(df, soda_sst, cord.UTM, df_na_rm, locations, temp_values)#open memory
df_long2 <- df_long %>%
  separate(col = ID, into = c("year", "month", "day"))

df_long2$year <- substr(as.character(df_long2$year), 2, 5)
head(df_long2, 30)
save(df_long2, file = "SODA_monthly_data.R")
```

I currently have mean monthly values for a ton of GPS points within a region.
For temperature values, I will first take a mean for each month over the whole region, so then I have a mean month/year value. region_*month*_mean_sst
Then, I will take mean of mean month/year of year of trawl to get a YEARLY mean to represent the whole region. region_year_mean_sst
For maximum temperature experienced in a year, I will take maximum of mean month/year and for minimum I will take minimum of mean month/year. region_year_max_sst, region_year_min_sst
I intend to look at 10 years of possible lags. 

Therefore, the next step is to merge these data with which regions link to which GPS points using hauls$region

First, I will make a lat lon region key

```{r}
latlongreg <- hauls %>%
  dplyr::select(lat, lon, region)
head(latlongreg)
```

Then I will link data table with GPS and date and temp with regions using above key, and then take appropriate averages

```{r}
date_temp_reg <- left_join(df_long2, latlongreg, by = c("lat", "lon"))
head(df_long2)
date_temp_reg_month_avg <- date_temp_reg %>%
  group_by(region, year, month) %>%
  summarize(region_month_mean_sst = mean(temp))
head(date_temp_reg_month_avg)

date_temp_reg_avg <- date_temp_reg_month_avg %>%
  group_by(region, year) %>%
  summarize(region_year_mean_sst = mean(region_month_mean_sst), region_year_max_sst = max(region_month_mean_sst), region_year_min_sst = min(region_month_mean_sst)) %>%
  mutate(region_year_seas_sst = region_year_max_sst - region_year_min_sst)
head(date_temp_reg_avg)

save(date_temp_reg_avg, date_temp_reg_month_avg, file = "date_ssttemp_avg_SODA.Rdata") #save this so i can start here!

ggplot(data=date_temp_reg_avg, aes(x=year, y=region_year_mean_sst)) +
  geom_point() +
  facet_wrap(~region)
base::nrow(date_temp_reg_avg)
```

I now have the predictor values I need, yearly min and max for entire region per year

Next step is to calculate change in temp from previous year to now, luckily I can farm this code from 27_acf_timeseries_analysis_covariates.R

I think I should calculate both change in temperature and lags from date_temp_reg_avg in order to keep years not actually surveyed (i.e. triennial west coast survey)

Here I am first adding lags
```{r}
#adding lag values (1, 2, 3, 4, 5) for seasonality and change in temperature
nm1 <- grep("*sst*", colnames(date_temp_reg_avg), value=TRUE)
nm2 <- paste("lag1", nm1, sep=".")
nm3 <- paste("lag2", nm1, sep=".")
nm4 <- paste("lag3", nm1, sep=".")
nm5 <- paste("lag4", nm1, sep=".")
nm6 <- paste("lag5", nm1, sep=".")
nm7 <- paste("lag6", nm1, sep=".")
nm8 <- paste("lag7", nm1, sep=".")
nm9 <- paste("lag8", nm1, sep=".")
nm10 <- paste("lag9", nm1, sep=".")
nm11 <- paste("lag10", nm1, sep=".")
date_temp_reg_avg_withlags <- data.table(date_temp_reg_avg)
date_temp_reg_avg_withlags[, (nm2) :=  data.table::shift(.SD, n=1, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm3) :=  data.table::shift(.SD, n=2, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm4) :=  data.table::shift(.SD, n=3, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm5) :=  data.table::shift(.SD, n=4, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm6) :=  data.table::shift(.SD, n=5, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm7) :=  data.table::shift(.SD, n=6, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm8) :=  data.table::shift(.SD, n=7, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm9) :=  data.table::shift(.SD, n=8, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm10) :=  data.table::shift(.SD, n=9, type = "lag"), by=reg, .SDcols=nm1]
date_temp_reg_avg_withlags[, (nm11) :=  data.table::shift(.SD, n=10, type = "lag"), by=reg, .SDcols=nm1]
```

Now, I'm adding change since last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change") := (region_year_mean_sst - lag1.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change") := (region_year_max_sst - lag1.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change") := (region_year_min_sst - lag1.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change") := (region_year_seas_sst - lag1.region_year_seas_sst)]
```
Change experienced last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag1") := (lag1.region_year_mean_sst - lag2.region_year_seas_sst)]
```
Change experienced 2 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag2") := (lag2.region_year_mean_sst - lag3.region_year_seas_sst)]
```
Change experienced 3 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag3") := (lag3.region_year_mean_sst - lag4.region_year_seas_sst)]
```
Change experienced 4 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag4") := (lag4.region_year_mean_sst - lag5.region_year_seas_sst)]
```
Change experienced 5 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag5") := (lag5.region_year_mean_sst - lag6.region_year_seas_sst)]
```
Change experienced 6 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag6") := (lag6.region_year_mean_sst - lag7.region_year_seas_sst)]
```
Change experienced 7 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag7") := (lag7.region_year_mean_sst - lag8.region_year_seas_sst)]
```
Change experienced 8 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag8") := (lag8.region_year_mean_sst - lag9.region_year_seas_sst)]
```
Change experienced 9 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag9") := (lag9.region_year_mean_sst - lag10.region_year_seas_sst)]
```
From Ryan's famous plot, we are more concerned with absolute value of change!
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_abs") := abs(sst_mean_change)]
date_temp_reg_avg_withlags[,c("sst_max_change_abs") := abs(sst_max_change)]
date_temp_reg_avg_withlags[,c("sst_min_change_abs") := abs(sst_min_change)]
date_temp_reg_avg_withlags[,c("sst_seas_change_abs") := abs(sst_seas_change)]
```
Abs Change experienced last year
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag1_abs") := abs(lag1.region_year_mean_sst - lag2.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag1_abs") := abs(lag1.region_year_max_sst - lag2.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag1_abs") := abs(lag1.region_year_min_sst - lag2.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag1_abs") := abs(lag1.region_year_seas_sst - lag2.region_year_seas_sst)]
```
Abs Change experienced 2 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag2_abs") := abs(lag2.region_year_mean_sst - lag3.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag2_abs") := abs(lag2.region_year_max_sst - lag3.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag2_abs") := abs(lag2.region_year_min_sst - lag3.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag2_abs") := abs(lag2.region_year_seas_sst - lag3.region_year_seas_sst)]
```
Abs Change experienced 3 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag3_abs") := abs(lag3.region_year_mean_sst - lag4.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag3_abs") := abs(lag3.region_year_max_sst - lag4.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag3_abs") := abs(lag3.region_year_min_sst - lag4.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag3_abs") := abs(lag3.region_year_seas_sst - lag4.region_year_seas_sst)]
```
Abs Change experienced 4 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag4_abs") := abs(lag4.region_year_mean_sst - lag5.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag4_abs") := abs(lag4.region_year_max_sst - lag5.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag4_abs") := abs(lag4.region_year_min_sst - lag5.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag4_abs") := abs(lag4.region_year_seas_sst - lag5.region_year_seas_sst)]
```
Abs Change experienced 5 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag5_abs") := abs(lag5.region_year_mean_sst - lag6.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag5_abs") := abs(lag5.region_year_max_sst - lag6.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag5_abs") := abs(lag5.region_year_min_sst - lag6.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag5_abs") := abs(lag5.region_year_seas_sst - lag6.region_year_seas_sst)]
```
Abs Change experienced 6 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag6_abs") := abs(lag6.region_year_mean_sst - lag7.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag6_abs") := abs(lag6.region_year_max_sst - lag7.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag6_abs") := abs(lag6.region_year_min_sst - lag7.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag6_abs") := abs(lag6.region_year_seas_sst - lag7.region_year_seas_sst)]
```
Abs Change experienced 7 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag7_abs") := abs(lag7.region_year_mean_sst - lag8.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag7_abs") := abs(lag7.region_year_max_sst - lag8.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag7_abs") := abs(lag7.region_year_min_sst - lag8.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag7_abs") := abs(lag7.region_year_seas_sst - lag8.region_year_seas_sst)]
```
Abs Change experienced 8 years ago
```{r}
date_temp_reg_avg_withlags[,c("sst_mean_change_lag8_abs") := abs(lag8.region_year_mean_sst - lag9.region_year_mean_sst)]
date_temp_reg_avg_withlags[,c("sst_max_change_lag8_abs") := abs(lag8.region_year_max_sst - lag9.region_year_max_sst)]
date_temp_reg_avg_withlags[,c("sst_min_change_lag8_abs") := abs(lag8.region_year_min_sst - lag9.region_year_min_sst)]
date_temp_reg_avg_withlags[,c("sst_seas_change_lag8_abs") := abs(lag8.region_year_seas_sst - lag9.region_year_seas_sst)]
```
Let's save all these goodies!!
```{r}
save(date_temp_reg_avg_withlags, file = "date_ssttemp_avg_SODA_withlags.Rdata")
```

Another way to look at lags, but this isn't appropriate for the binomials I'm currently looking at

```{r}
ccf()
```
